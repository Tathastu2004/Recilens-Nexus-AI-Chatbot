// /controllers/chatController.js
import ChatSession from '../models/ChatSession.js';
import Message from '../models/Message.js';
import fs from 'fs';
import path from 'path';
import { v2 as cloudinary } from 'cloudinary'; // ‚úÖ Direct import
import { getAIResponse } from '../services/aiService.js';
import fetch from 'node-fetch';
import { fileURLToPath } from 'url';
import { dirname } from 'path';
import crypto from 'crypto';
import { cacheService } from '../services/cacheService.js';


// import { extractTextFromFile } from '../utils/textExtraction.js';

// Get __dirname equivalent for ES modules

const __filename = fileURLToPath(import.meta.url);
const __dirname = dirname(__filename);

// ‚úÖ CONFIGURE CLOUDINARY DIRECTLY
cloudinary.config({
  cloud_name: process.env.CLOUDINARY_CLOUD_NAME,
  api_key: process.env.CLOUDINARY_API_KEY,
  api_secret: process.env.CLOUDINARY_API_SECRET
});

// ‚úÖ CREATE MISSING FUNCTIONS LOCALLY
const generateFileHash = (fileBuffer) => {
  try {
    return crypto.createHash('md5').update(fileBuffer).digest('hex');
  } catch (error) {
    console.error('‚ùå [HASH] Failed to generate file hash:', error.message);
    return 'hash_failed_' + Date.now() + '_' + Math.random().toString(36).substr(2, 9);
  }
};

const uploadWithDeduplication = async (filePath, options = {}) => {
  try {
    console.log('‚òÅÔ∏è [DEDUP] Starting upload with deduplication...');
    
    // Read file and generate hash
    const fileBuffer = fs.readFileSync(filePath);
    const fileHash = generateFileHash(fileBuffer);
    
    console.log('üîç [DEDUP] File hash generated:', fileHash.substring(0, 8) + '...');
    
    // Check for existing file with same hash (simplified check)
    try {
      const searchResult = await cloudinary.search
        .expression(`tags=${fileHash}`)
        .max_results(1)
        .execute();
      
      if (searchResult.resources && searchResult.resources.length > 0) {
        const existingFile = searchResult.resources[0];
        console.log('‚ôªÔ∏è [DEDUP] Duplicate found, reusing existing file:', existingFile.public_id);
        
        return {
          ...existingFile,
          isDuplicate: true,
          originalHash: fileHash,
          message: 'Duplicate file found, reusing existing upload'
        };
      }
    } catch (searchError) {
      console.warn('‚ö†Ô∏è [DEDUP] Search failed, proceeding with new upload:', searchError.message);
    }
    
    // Upload new file with hash tag
    console.log('üì§ [DEDUP] Uploading new file...');
    const uploadResult = await cloudinary.uploader.upload(filePath, {
      ...options,
      tags: [...(options.tags || []), fileHash, 'nexus_chat'],
      context: {
        ...options.context,
        file_hash: fileHash,
        uploaded_at: new Date().toISOString()
      }
    });
    
    console.log('‚úÖ [DEDUP] New file uploaded successfully:', uploadResult.public_id);
    
    return {
      ...uploadResult,
      isDuplicate: false,
      originalHash: fileHash,
      message: 'New file uploaded successfully'
    };
    
  } catch (error) {
    console.error('‚ùå [DEDUP] Upload with deduplication failed:', error.message);
    throw error;
  }
};

// üîπ Create new chat session
export const createChatSession = async (req, res) => {
  try {
    const newSession = new ChatSession({
      user: req.user._id,
      title: req.body.title || 'New Chat'
    });
    const saved = await newSession.save();
    res.status(201).json(saved);
  } catch (error) {
    res.status(500).json({ message: 'Server error creating chat session' });
  }
};

// üîπ Get all user chat sessions
export const getUserChatSessions = async (req, res) => {
  try {
    const sessions = await ChatSession.find({ user: req.user._id }).sort({ createdAt: -1 });
    res.status(200).json(sessions);
  } catch (error) {
    res.status(500).json({ message: 'Failed to fetch sessions' });
  }
};

// üîπ Get messages in a session
export const getSessionMessages = async (req, res) => {
  try {
    const sessionId = req.params.sessionId;
    const messages = await Message.find({ session: sessionId }).sort({ createdAt: 1 });
    res.status(200).json(messages);
  } catch (error) {
    res.status(500).json({ message: 'Error retrieving messages' });
  }
};

// üîπ Update session title
export const updateSessionTitle = async (req, res) => {
  try {
    const { sessionId } = req.params;
    const { title } = req.body;
    const updatedSession = await ChatSession.findOneAndUpdate(
      { _id: sessionId, user: req.user._id },
      { title, updatedAt: new Date() },
      { new: true }
    );
    if (!updatedSession) return res.status(404).json({ message: 'Session not found or unauthorized' });
    res.json({ success: true, session: updatedSession });
  } catch (error) {
    res.status(500).json({ message: 'Failed to update session title' });
  }
};

// üîπ Delete chat session
export const deleteChatSession = async (req, res) => {
  try {
    const { sessionId } = req.params;
    const userId = req.user._id;

    const messages = await Message.find({ session: sessionId });
    const publicIds = messages
      .map(msg => msg.fileUrl?.match(/\/upload\/(?:v\d+\/)?(.+)\.\w+$/)?.[1])
      .filter(Boolean);

    if (publicIds.length > 0) await cloudinary.api.delete_resources(publicIds);
    await Message.deleteMany({ session: sessionId });
    const deletedSession = await ChatSession.findOneAndDelete({ _id: sessionId, user: userId });
    if (!deletedSession) return res.status(404).json({ message: 'Session not found or unauthorized' });

    res.json({ success: true, message: 'Session and files deleted successfully' });
  } catch (error) {
    res.status(500).json({ message: 'Failed to delete session' });
  }
};

// üîπ Enhanced Upload file handler with deduplication AND text extraction
// üîπ Enhanced Upload file handler - REDESIGNED AND SIMPLIFIED
export const uploadFileHandler = async (req, res) => {
  console.log('üì§ [UPLOAD] Starting file upload process...');
  
  try {
    // ‚úÖ VALIDATE FILE EXISTS
    if (!req.file) {
      console.error('‚ùå [UPLOAD] No file provided in request');
      return res.status(400).json({ 
        success: false, 
        message: 'No file uploaded' 
      });
    }

    console.log('üìã [UPLOAD] File received:', {
      originalName: req.file.originalname,
      size: `${(req.file.size / 1024 / 1024).toFixed(2)} MB`,
      mimetype: req.file.mimetype,
      path: req.file.path
    });

    // ‚úÖ DETECT FILE TYPE
    const getFileType = (mimetype, filename) => {
      const ext = path.extname(filename).toLowerCase();
      console.log('üîç [UPLOAD] Analyzing file type:', { ext, mimetype });
      
      if (mimetype.startsWith('image/') || ['.jpg', '.jpeg', '.png', '.gif', '.webp', '.bmp'].includes(ext)) {
        return 'image';
      }
      if (mimetype.includes('pdf') || ext === '.pdf') return 'document';
      if (['.docx', '.doc', '.txt'].includes(ext)) return 'document';
      
      return 'document'; // Default fallback
    };

    const fileType = getFileType(req.file.mimetype, req.file.originalname);
    const fileExtension = path.extname(req.file.originalname).toLowerCase();
    
    console.log('‚úÖ [UPLOAD] File type detected:', { fileType, fileExtension });

    // ‚úÖ READ FILE BUFFER FOR PROCESSING
    const fileBuffer = fs.readFileSync(req.file.path);
    const fileHash = generateFileHash(fileBuffer);
    
    console.log('üîê [UPLOAD] File hash generated:', fileHash.substring(0, 12) + '...');

    let uploadResult;
    let extractedText = null;

    // ‚úÖ UPLOAD TO CLOUDINARY
    try {
      console.log('‚òÅÔ∏è [UPLOAD] Uploading to Cloudinary...');
      
      uploadResult = await cloudinary.uploader.upload(req.file.path, {
        folder: 'nexus_chat_files',
        resource_type: fileType === 'image' ? 'image' : 'raw',
        use_filename: true,
        unique_filename: true,
        access_mode: 'public',
        tags: ['nexus_chat', fileHash],
        timeout: 60000
      });

      console.log('‚úÖ [UPLOAD] Cloudinary upload successful:', {
        public_id: uploadResult.public_id,
        secure_url: uploadResult.secure_url,
        bytes: uploadResult.bytes
      });

    } catch (uploadError) {
      console.error('‚ùå [UPLOAD] Cloudinary upload failed:', uploadError.message);
      throw new Error(`Upload failed: ${uploadError.message}`);
    }

    // ‚úÖ EXTRACT TEXT FROM DOCUMENTS
    if (fileType === 'document') {
      console.log('üìÑ [EXTRACTION] Starting text extraction for document...');
      
      try {
        if (fileExtension === '.pdf') {
          console.log('üìÑ [PDF] Processing PDF file...');
          
          try {
            // ‚úÖ IMPORT AND USE THE CLEAN PDF PARSER
            const { parsePdf } = await import('../utils/pdfParser.js');
            const pdfBuffer = fs.readFileSync(req.file.path);
            
            console.log('üìÑ [PDF] Using clean PDF parser...');
            extractedText = await parsePdf(pdfBuffer);
            
            if (extractedText && extractedText.length > 50 && !extractedText.includes('extraction failed')) {
              console.log('‚úÖ [PDF] Clean PDF parser extraction successful:', {
                textLength: extractedText.length,
                preview: extractedText.substring(0, 300) + '...',
                firstWords: extractedText.split(' ').slice(0, 15).join(' ')
              });
            } else {
              console.log('‚ö†Ô∏è [PDF] PDF appears to be image-based or extraction failed');
              extractedText = '‚ö†Ô∏è PDF appears to be image-based or contains no readable text.';
            }
            
          } catch (pdfError) {
            console.error('‚ùå [PDF] Clean PDF parser failed:', pdfError.message);
            extractedText = `‚ùå PDF text extraction failed: ${pdfError.message}`;
          }
          
        } else if (fileExtension === '.txt') {
          console.log('üìÑ [TXT] Extracting text from TXT file...');
          
          try {
            extractedText = fs.readFileSync(req.file.path, 'utf-8').trim();
            
            console.log('‚úÖ [TXT] Text extraction successful:', {
              characters: extractedText.length,
              preview: extractedText.substring(0, 200) + '...'
            });
          } catch (txtError) {
            console.error('‚ùå [TXT] Text extraction failed:', txtError.message);
            extractedText = `‚ùå TXT extraction failed: ${txtError.message}`;
          }
          
        } else {
          console.log('‚ö†Ô∏è [EXTRACTION] Unsupported document type:', fileExtension);
          extractedText = `‚ùå Text extraction not supported for ${fileExtension} files`;
        }
        
      } catch (extractError) {
        console.error('‚ùå [EXTRACTION] Text extraction failed:', extractError.message);
        extractedText = `‚ùå Text extraction failed: ${extractError.message}`;
      }
    } else {
      console.log('‚ÑπÔ∏è [EXTRACTION] Skipping text extraction for non-document file');
      extractedText = null;
    }

    // ‚úÖ CLEANUP TEMPORARY FILE
    try {
      if (fs.existsSync(req.file.path)) {
        fs.unlinkSync(req.file.path);
        console.log('üßπ [CLEANUP] Temporary file removed:', req.file.path);
      }
    } catch (cleanupError) {
      console.warn('‚ö†Ô∏è [CLEANUP] Failed to remove temp file:', cleanupError.message);
    }

    // ‚úÖ PREPARE RESPONSE AND STORE IN REDIS
    const hasValidText = extractedText && !extractedText.startsWith('‚ùå');
    const uploadId = `upload_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

    const cacheData = {
      extractedText: hasValidText ? extractedText : null,
      fileUrl: uploadResult.secure_url,
      fileName: req.file.originalname,
      fileType,
      timestamp: new Date().toISOString(),
      hasValidText
    };

    // ‚úÖ STORE IN REDIS CACHE (20 minutes TTL)
    await cacheService.storeExtractedText(uploadId, cacheData);

    // ‚úÖ AUTO-TRIGGER AI ANALYSIS IF TEXT WAS EXTRACTED
    let aiAnalysis = null;
    if (hasValidText) {
      console.log('ü§ñ [UPLOAD] Text extracted successfully, triggering immediate AI analysis...');
      console.log('üìÑ [UPLOAD] Extracted text ready for direct processing:', {
        textLength: extractedText.length,
        textPreview: extractedText.substring(0, 200) + '...',
        fileName: req.file.originalname
      });
      
      try {
        // ‚úÖ CREATE OR GET SESSION
        let sessionId = req.body.sessionId;
        const userId = req.user._id;
        
        if (!sessionId) {
          console.log('üìù [UPLOAD] Creating new session for direct analysis...');
          const newSession = new ChatSession({
            user: userId,
            title: `Analysis: ${req.file.originalname}`,
            createdAt: new Date()
          });
          const savedSession = await newSession.save();
          sessionId = savedSession._id;
          console.log('‚úÖ [UPLOAD] New session created:', sessionId);
        }

        // ‚úÖ CREATE USER MESSAGE
        console.log('üíæ [UPLOAD] Creating user message for direct analysis...');
        const userMessage = new Message({
          session: sessionId,
          sender: userId,
          message: `üìÑ Uploaded and analyzing: ${req.file.originalname}`,
          type: 'document',
          fileUrl: uploadResult.secure_url,
          fileType: fileType,
          fileName: req.file.originalname
        });

        await userMessage.save();
        console.log('‚úÖ [UPLOAD] User message saved:', userMessage._id);

        // ‚úÖ CALL AI SERVICE DIRECTLY WITH EXTRACTED TEXT
        console.log('ü§ñ [UPLOAD] Calling AI service directly with extracted text...');
        console.log('üîç [UPLOAD] Passing to AI service:', {
          messageLength: 47, // "Please analyze this document: filename.pdf"
          extractedTextLength: extractedText.length, // ‚úÖ YOUR 4069 CHARACTERS
          extractedTextType: typeof extractedText,
          directPass: true,
          noRedisLookup: true
        });

        const analysisPrompt = `Please analyze this document comprehensively:

Document: ${req.file.originalname}
Type: ${fileType}

Please provide:
1. Document overview and purpose
2. Key topics and main points  
3. Important details or findings
4. Notable sections or highlights
5. Summary of content

Document content to analyze:`;

        // ‚úÖ DIRECT AI SERVICE CALL - NO REDIS INVOLVED
        const aiResponse = await getAIResponse({
          message: analysisPrompt,
          extractedText: extractedText, // ‚úÖ PASS DIRECTLY - 4069 CHARACTERS
          type: 'document',
          fileUrl: uploadResult.secure_url,
          fileType: fileType,
          fileName: req.file.originalname,
          sessionId: sessionId,
          conversationContext: []
        });

        console.log('‚úÖ [UPLOAD] Direct AI analysis completed:', {
          aiResponseLength: aiResponse?.length || 0,
          aiResponsePreview: aiResponse ? aiResponse.substring(0, 200) + '...' : null,
          processingMethod: 'direct_extraction'
        });

        // ‚úÖ CREATE AI MESSAGE
        console.log('üíæ [UPLOAD] Saving AI analysis to database...');
        const aiMessage = new Message({
          session: sessionId,
          sender: 'AI',
          message: aiResponse || 'Unable to analyze document at this time.',
          type: 'document',
          completedBy: 'Llama3 + Direct Text Extraction',
          metadata: {
            autoGenerated: true,
            usedDirectExtraction: true,
            extractedTextLength: extractedText.length,
            analysisType: 'immediate_document_analysis',
            processingTime: new Date().toISOString()
          }
        });

        await aiMessage.save();
        console.log('‚úÖ [UPLOAD] AI analysis saved:', aiMessage._id);

        // ‚úÖ PREPARE ANALYSIS RESULTS
        aiAnalysis = {
          success: true,
          method: 'direct_extraction',
          sessionId: sessionId,
          userMessage: {
            _id: userMessage._id,
            message: userMessage.message,
            timestamp: userMessage.createdAt
          },
          aiMessage: {
            _id: aiMessage._id,
            message: aiMessage.message,
            timestamp: aiMessage.createdAt,
            completedBy: aiMessage.completedBy,
            extractedTextLength: extractedText.length
          }
        };

      } catch (aiError) {
        console.error('‚ùå [UPLOAD] Direct AI analysis failed:', {
          error: aiError.message,
          stack: aiError.stack,
          extractedTextLength: extractedText?.length || 0
        });
        
        aiAnalysis = {
          success: false,
          method: 'direct_extraction',
          error: 'AI analysis failed',
          details: aiError.message,
          extractedTextLength: extractedText?.length || 0
        };
      }
    }

    const response = {
      success: true,
      message: hasValidText ? 
        'File uploaded, text extracted, and AI analysis completed' : 
        'File uploaded successfully',
      fileUrl: uploadResult.secure_url,
      fileName: req.file.originalname,
      fileType,
      fileSize: req.file.size,
      extractedText: null, // ‚úÖ DON'T SEND FULL TEXT TO FRONTEND
      hasExtractedText: hasValidText,
      textLength: extractedText?.length || 0,
      uploadId: uploadId,
      timestamp: new Date().toISOString(),
      cached: true,
      cacheTTL: '20 minutes',
      // ‚úÖ INCLUDE AI ANALYSIS RESULTS
      aiAnalysis: aiAnalysis,
      autoAnalyzed: !!aiAnalysis && !aiAnalysis.error
    };

    console.log('‚úÖ [UPLOAD] Upload process completed with auto AI analysis:', {
      fileName: req.file.originalname,
      fileType,
      hasExtractedText: hasValidText,
      textLength: extractedText?.length || 0,
      uploadId: uploadId.substring(0, 12) + '...',
      cached: true,
      autoAnalyzed: response.autoAnalyzed,
      sessionId: aiAnalysis?.sessionId ? aiAnalysis.sessionId.toString().substring(0, 8) + '...' : null
    });

    res.status(200).json(response);
    
  } catch (error) {
    console.error('‚ùå [UPLOAD] Upload process failed:', error.message);
    console.error('‚ùå [UPLOAD] Error stack:', error.stack);
    
    // ‚úÖ CLEANUP ON ERROR
    if (req.file?.path && fs.existsSync(req.file.path)) {
      try {
        fs.unlinkSync(req.file.path);
        console.log('üßπ [CLEANUP] Temporary file removed after error');
      } catch (cleanupError) {
        console.warn('‚ö†Ô∏è [CLEANUP] Failed to cleanup after error:', cleanupError.message);
      }
    }
    
    res.status(500).json({
      success: false,
      message: 'File upload and processing failed',
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
};

// üîπ Stream AI response over HTTP with full context support - ENHANCED WITH TEXT EXTRACTION
export const sendMessage = async (req, res) => {
  console.log('üö® [DEBUG] sendMessage function TRIGGERED!');
  console.log('üö® [DEBUG] Request method:', req.method);
  console.log('üö® [DEBUG] Request URL:', req.url);
  console.log('üö® [DEBUG] Request body exists:', !!req.body);
  
  console.log('üöÄ [SEND MESSAGE] ==================== STARTING SEND MESSAGE ====================');
  console.log('üì• [SEND MESSAGE] Raw request body:', JSON.stringify(req.body, null, 2));
  console.log('üì• [SEND MESSAGE] Request headers:', req.headers);
  
  try {
    const { sessionId, message, type, fileUrl, fileType, fileName } = req.body;
    // ‚úÖ REMOVED: uploadId logic since we're doing direct analysis
    
    const userId = req.user._id;

    // ‚úÖ VALIDATE REQUIRED FIELDS
    if (!sessionId || !message) {
      console.error('‚ùå [SEND MESSAGE] Validation failed - missing required fields');
      return res.status(400).json({
        success: false,
        error: 'Session ID and message are required'
      });
    }

    // ‚úÖ VERIFY SESSION EXISTS AND USER HAS ACCESS
    console.log('üîç [SEND MESSAGE] Checking session access...');
    const session = await ChatSession.findById(sessionId);
    if (!session || session.user.toString() !== userId.toString()) {
      console.error('‚ùå [SEND MESSAGE] Session access denied:', {
        sessionFound: !!session,
        sessionUser: session?.user?.toString(),
        requestUser: userId.toString()
      });
      return res.status(403).json({
        success: false,
        error: 'Session not found or access denied'
      });
    }
    console.log('‚úÖ [SEND MESSAGE] Session access verified');

    // ‚úÖ CREATE USER MESSAGE (No extracted text lookup needed)
    console.log('üíæ [SEND MESSAGE] Creating user message in database...');
    const userMessage = new Message({
      session: sessionId,
      sender: userId,
      message,
      type: type || 'text',
      fileUrl: fileUrl || null,
      fileType: fileType || null,
      fileName: fileName || null
    });

    await userMessage.save();
    console.log('‚úÖ [SEND MESSAGE] User message saved:', userMessage._id);

    // ‚úÖ CALL AI SERVICE (No extracted text - for regular chat)
    console.log('ü§ñ [SEND MESSAGE] Calling AI service for regular chat...');
    const aiResponse = await getAIResponse({
      message,
      extractedText: null, // ‚úÖ No extracted text for regular messages
      type: type || 'text',
      fileUrl,
      fileType,
      fileName,
      sessionId
    });

    // ‚úÖ CREATE AI MESSAGE IN DATABASE
    console.log('üíæ [SEND MESSAGE] Creating AI message in database...');
    const aiMessage = new Message({
      session: sessionId,
      sender: 'AI',
      message: aiResponse || 'No response generated',
      type: type || 'text',
      completedBy: type === 'image' ? 'BLIP' : type === 'document' ? 'Llama3 + Document Processing' : 'Llama3',
      metadata: {
        usedExtractedText: false, // ‚úÖ FIXED: Set to false since no extracted text in sendMessage
        extractedTextLength: 0    // ‚úÖ FIXED: Set to 0 since no extracted text
      }
    });

    await aiMessage.save();
    console.log('‚úÖ [SEND MESSAGE] AI message saved to database:', aiMessage._id);

    // ‚úÖ UPDATE SESSION ACTIVITY
    session.lastActivity = new Date();
    await session.save();
    console.log('‚úÖ [SEND MESSAGE] Session activity updated');

    // ‚úÖ RETURN SUCCESS RESPONSE
    const responseData = {
      success: true,
      userMessage: {
        _id: userMessage._id,
        message: userMessage.message,
        sender: 'user',
        timestamp: userMessage.createdAt,
        type: userMessage.type,
        fileUrl: userMessage.fileUrl,
        fileType: userMessage.fileType,
        fileName: userMessage.fileName,
        hasTextExtraction: userMessage.hasTextExtraction,
        extractedTextLength: userMessage.textLength
      },
      aiMessage: {
        _id: aiMessage._id,
        message: aiMessage.message,
        sender: 'AI',
        timestamp: aiMessage.createdAt,
        type: aiMessage.type,
        completedBy: aiMessage.completedBy
      }
    };

    console.log('‚úÖ [SEND MESSAGE] Response ready:', {
      success: true,
      userMessageId: responseData.userMessage._id,
      aiMessageId: responseData.aiMessage._id,
      aiResponseLength: responseData.aiMessage.message.length
    });
    console.log('üèÅ [SEND MESSAGE] ==================== SEND MESSAGE COMPLETED ====================');

    res.json(responseData);

  } catch (error) {
    console.error('‚ùå [SEND MESSAGE] ==================== ERROR OCCURRED ====================');
    console.error('‚ùå [SEND MESSAGE] Error name:', error.name);
    console.error('‚ùå [SEND MESSAGE] Error message:', error.message);
    console.error('‚ùå [SEND MESSAGE] Error stack:', error.stack);
    console.error('‚ùå [SEND MESSAGE] Request body that caused error:', JSON.stringify(req.body, null, 2));
    
    res.status(500).json({
      success: false,
      error: 'Failed to send message',
      details: error.message,
      timestamp: new Date().toISOString()
    });
  }
};

// ‚úÖ NEW: Get file type validation
export const validateFileType = async (req, res) => {
  try {
    const { fileName, fileType } = req.body;
    
    const supportedTypes = {
      images: ['.png', '.jpg', '.jpeg', '.webp', '.gif', '.bmp', '.svg'],
      documents: ['.pdf', '.docx', '.doc', '.txt']
    };
    
    const ext = path.extname(fileName).toLowerCase();
    const isImage = supportedTypes.images.includes(ext);
    const isDocument = supportedTypes.documents.includes(ext);
    
    res.json({
      isValid: isImage || isDocument,
      detectedType: isImage ? 'image' : isDocument ? 'document' : 'unknown',
      supportedTypes,
      canExtractText: isDocument
    });
    
  } catch (error) {
    res.status(500).json({ error: 'Validation failed' });
  }
};

// ‚úÖ NEW: Get session statistics
export const getSessionStats = async (req, res) => {
  try {
    const { sessionId } = req.params;
    
    const messages = await Message.find({ session: sessionId }).lean();
    
    const stats = {
      totalMessages: messages.length,
      userMessages: messages.filter(m => m.sender !== 'AI').length,
      aiMessages: messages.filter(m => m.sender === 'AI').length,
      imageMessages: messages.filter(m => m.type === 'image').length,
      documentMessages: messages.filter(m => m.type === 'document').length,
      filesUploaded: messages.filter(m => m.fileUrl).length,
      // ‚úÖ NEW: Text extraction stats
      documentsWithText: messages.filter(m => m.extractedText && !m.extractedText.startsWith('‚ùå')).length,
      totalExtractedChars: messages.reduce((sum, m) => sum + (m.extractedText?.length || 0), 0)
    };
    
    res.json(stats);
    
  } catch (error) {
    res.status(500).json({ error: 'Failed to get session stats' });
  }
};

// ‚úÖ NEW: Get duplicate files statistics
export const getDuplicateStats = async (req, res) => {
  try {
    // Get all files with duplicate tags
    const duplicateSearch = await cloudinary.search
      .expression('tags:nexus_chat')
      .with_field('tags')
      .with_field('context')
      .max_results(500)
      .execute();

    const filesByHash = {};
    let totalFiles = 0;
    let duplicateFiles = 0;
    let savedBandwidth = 0;

    duplicateSearch.resources.forEach(file => {
      totalFiles++;
      const hash = file.tags?.find(tag => tag.length === 32); // MD5 hash length
      
      if (hash) {
        if (!filesByHash[hash]) {
          filesByHash[hash] = [];
        }
        filesByHash[hash].push(file);
        
        if (filesByHash[hash].length > 1) {
          duplicateFiles++;
          savedBandwidth += file.bytes || 0;
        }
      }
    });

    const duplicateGroups = Object.values(filesByHash).filter(group => group.length > 1);

    res.json({
      success: true,
      stats: {
        totalFiles,
        uniqueFiles: Object.keys(filesByHash).length,
        duplicateFiles,
        duplicateGroups: duplicateGroups.length,
        savedBandwidth,
        savedBandwidthMB: (savedBandwidth / (1024 * 1024)).toFixed(2),
        topDuplicates: duplicateGroups
          .sort((a, b) => b.length - a.length)
          .slice(0, 5)
          .map(group => ({
            hash: group[0].tags?.find(tag => tag.length === 32),
            count: group.length,
            firstUpload: group[0].created_at,
            lastUpload: group[group.length - 1].created_at,
            totalSize: group.reduce((sum, file) => sum + (file.bytes || 0), 0)
          }))
      }
    });

  } catch (error) {
    console.error('‚ùå [DUPLICATE STATS] Error:', error.message);
    res.status(500).json({ 
      success: false, 
      error: 'Failed to get duplicate statistics' 
    });
  }
};

// ‚úÖ NEW: Clean up duplicate files (keep only the first one)
export const cleanupDuplicates = async (req, res) => {
  try {
    const { dryRun = true } = req.query; // Default to dry run for safety
    
    console.log('üßπ [CLEANUP] Starting duplicate cleanup...', { dryRun });
    
    const duplicateSearch = await cloudinary.search
      .expression('tags:nexus_chat')
      .with_field('tags')
      .with_field('context')
      .sort_by([['created_at', 'asc']])
      .max_results(500)
      .execute();

    const filesByHash = {};
    
    // Group files by hash
    duplicateSearch.resources.forEach(file => {
      const hash = file.tags?.find(tag => tag.length === 32);
      if (hash) {
        if (!filesByHash[hash]) {
          filesByHash[hash] = [];
        }
        filesByHash[hash].push(file);
      }
    });

    const duplicateGroups = Object.values(filesByHash).filter(group => group.length > 1);
    let deletedFiles = 0;
    let savedSpace = 0;
    const deletedPublicIds = [];

    for (const group of duplicateGroups) {
      // Keep the first file (oldest), delete the rest
      const [keepFile, ...deleteFiles] = group;
      
      console.log(`üìã [CLEANUP] Hash group: ${keepFile.tags?.find(tag => tag.length === 32)?.substring(0, 8)}... - Keep: ${keepFile.public_id}, Delete: ${deleteFiles.length} files`);
      
      for (const file of deleteFiles) {
        if (!dryRun) {
          try {
            await cloudinary.uploader.destroy(file.public_id);
            console.log(`üóëÔ∏è [CLEANUP] Deleted: ${file.public_id}`);
          } catch (deleteError) {
            console.error(`‚ùå [CLEANUP] Failed to delete ${file.public_id}:`, deleteError.message);
            continue;
          }
        }
        
        deletedFiles++;
        savedSpace += file.bytes || 0;
        deletedPublicIds.push(file.public_id);
      }
    }

    res.json({
      success: true,
      cleanup: {
        dryRun,
        duplicateGroups: duplicateGroups.length,
        deletedFiles,
        savedSpace,
        savedSpaceMB: (savedSpace / (1024 * 1024)).toFixed(2),
        deletedPublicIds: dryRun ? deletedPublicIds : deletedPublicIds.slice(0, 10), // Limit output in actual run
        message: dryRun ? 
          `Dry run completed. Would delete ${deletedFiles} duplicate files (${(savedSpace / (1024 * 1024)).toFixed(2)} MB)` :
          `Deleted ${deletedFiles} duplicate files, saved ${(savedSpace / (1024 * 1024)).toFixed(2)} MB`
      }
    });

  } catch (error) {
    console.error('‚ùå [CLEANUP] Error:', error.message);
    res.status(500).json({ 
      success: false, 
      error: 'Failed to cleanup duplicates' 
    });
  }
};
